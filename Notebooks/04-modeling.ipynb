{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmNX2YVEsM4k",
        "outputId": "a40adc00-0192-4111-8437-9522e8190233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: tf2onnx in /usr/local/lib/python3.12/dist-packages (1.16.1)\n",
            "Requirement already satisfied: skl2onnx in /usr/local/lib/python3.12/dist-packages (1.19.1)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.12/dist-packages (1.17.0)\n",
            "Requirement already satisfied: onnxmltools in /usr/local/lib/python3.12/dist-packages (1.14.0)\n",
            "Requirement already satisfied: keras_tuner in /usr/local/lib/python3.12/dist-packages (1.4.8)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.11.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from tf2onnx) (1.17.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.12/dist-packages (from tf2onnx) (25.9.23)\n",
            "Requirement already satisfied: protobuf~=3.20 in /usr/local/lib/python3.12/dist-packages (from tf2onnx) (3.20.3)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (from keras_tuner) (3.10.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.12/dist-packages (from keras_tuner) (1.0.5)\n",
            "Requirement already satisfied: grpcio in /usr/local/lib/python3.12/dist-packages (from keras_tuner) (1.76.0)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio->keras_tuner) (4.15.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (0.18.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (0.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras_tuner) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras_tuner) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas numpy matplotlib seaborn scikit-learn requests tf2onnx skl2onnx onnx onnxmltools keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cU-WnhTQ45fp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import joblib\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks\n",
        "\n",
        "# Conversion Libs\n",
        "try:\n",
        "    import tf2onnx\n",
        "    import onnxmltools\n",
        "    from skl2onnx import convert_sklearn\n",
        "    from skl2onnx.common.data_types import FloatTensorType\n",
        "    ONNX_AVAILABLE = True\n",
        "except ImportError:\n",
        "    ONNX_AVAILABLE = False\n",
        "    print(\"Warning: ONNX libraries not found. ONNX export will be skipped.\")\n",
        "\n",
        "# Setup\n",
        "PROCESSED_DIR = 'data/processed'\n",
        "MODELS_DIR = 'models'\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "\n",
        "# Load Data\n",
        "print(\"Loading data...\")\n",
        "X = np.load(os.path.join(PROCESSED_DIR, 'X.npy'))\n",
        "y = np.load(os.path.join(PROCESSED_DIR, 'y.npy'))\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Save Test Set (if not already done)\n",
        "np.save(os.path.join(PROCESSED_DIR, 'X_test.npy'), X_test)\n",
        "np.save(os.path.join(PROCESSED_DIR, 'y_test.npy'), y_test)\n",
        "\n",
        "# Flatten for ML models\n",
        "X_train_flat = np.hstack([np.mean(X_train, axis=1), np.std(X_train, axis=1)])\n",
        "X_test_flat = np.hstack([np.mean(X_test, axis=1), np.std(X_test, axis=1)])\n",
        "\n",
        "# One-hot for DL\n",
        "y_train_cat = keras.utils.to_categorical(y_train, 12)\n",
        "y_test_cat = keras.utils.to_categorical(y_test, 12)\n",
        "input_shape_dl = (100, 23)\n",
        "\n",
        "# --- Helper: Model Saver ---\n",
        "def save_model_safely(model, name, model_type='keras', input_shape=None):\n",
        "    path_root = os.path.join(MODELS_DIR, name)\n",
        "    print(f\"Saving {name}...\")\n",
        "    try:\n",
        "        if model_type == 'keras':\n",
        "            model.save(f\"{path_root}.h5\")\n",
        "        else:\n",
        "            joblib.dump(model, f\"{path_root}.joblib\")\n",
        "        print(f\" - Native saved: {name}\")\n",
        "    except Exception as e:\n",
        "        print(f\" ! Error saving native model {name}: {e}\")\n",
        "\n",
        "    # if not ONNX_AVAILABLE: return\n",
        "\n",
        "    # try:\n",
        "    #     if model_type == 'sklearn':\n",
        "    #         initial_type = [('float_input', FloatTensorType([None, input_shape]))]\n",
        "    #         onnx_model = convert_sklearn(model, initial_types=initial_type)\n",
        "    #         with open(f\"{path_root}.onnx\", \"wb\") as f:\n",
        "    #             f.write(onnx_model.SerializeToString())\n",
        "    #     elif model_type == 'xgboost':\n",
        "    #         initial_type = [('float_input', FloatTensorType([None, input_shape]))]\n",
        "    #         onnx_model = onnxmltools.convert_xgboost(model, initial_types=initial_type)\n",
        "    #         with open(f\"{path_root}.onnx\", \"wb\") as f:\n",
        "    #             f.write(onnx_model.SerializeToString())\n",
        "    #     elif model_type == 'keras':\n",
        "    #         spec = (tf.TensorSpec((None, *input_shape), tf.float32, name=\"input\"),)\n",
        "    #         tf2onnx.convert.from_keras(model, input_signature=spec, output_path=f\"{path_root}.onnx\")\n",
        "    #     print(f\" - ONNX saved: {name}\")\n",
        "    # except Exception as e:\n",
        "    #     print(f\" ! Error converting {name} to ONNX: {e}\")\n",
        "\n",
        "# --- Helper: DL Hyperparameter Random Search ---\n",
        "def run_dl_random_search(build_fn, param_grid, n_iter=3):\n",
        "    \"\"\"Simple custom random search for Keras models.\"\"\"\n",
        "    import random\n",
        "    best_model = None\n",
        "    best_acc = 0.0\n",
        "    best_params = {}\n",
        "\n",
        "    print(f\"Starting Random Search (n_iter={n_iter})...\")\n",
        "\n",
        "    for i in range(n_iter):\n",
        "        # Sample params\n",
        "        params = {k: random.choice(v) for k, v in param_grid.items()}\n",
        "        print(f\"Trial {i+1}/{n_iter}: {params}\")\n",
        "\n",
        "        # Build & Train (Quick train for selection)\n",
        "        model = build_fn(**params)\n",
        "\n",
        "        # Use early stopping for the search to save time\n",
        "        es = callbacks.EarlyStopping(monitor='val_accuracy', patience=2, verbose=0)\n",
        "\n",
        "        history = model.fit(\n",
        "            X_train, y_train_cat,\n",
        "            epochs=5, # Short epochs for search\n",
        "            batch_size=64,\n",
        "            validation_split=0.1,\n",
        "            callbacks=[es],\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        val_acc = max(history.history['val_accuracy'])\n",
        "        print(f\" - Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model = model # Note: this model is only partially trained\n",
        "            best_params = params\n",
        "\n",
        "    print(f\"Best Params: {best_params} (Val Acc: {best_acc:.4f})\")\n",
        "\n",
        "    # Re-build and fully train the best configuration\n",
        "    final_model = build_fn(**best_params)\n",
        "    return final_model, best_params\n",
        "\n",
        "\n",
        "# ==================================================================================\n",
        "# 1. Random Forest (with Manual \"Early Stopping\" loop & Tuning)\n",
        "# ==================================================================================\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"1. Random Forest\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Step A: Hyperparameter Tuning (RandomizedSearchCV)\n",
        "rf_params = {\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "# We use a smaller n_estimators for tuning to be fast\n",
        "rf_base = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "rf_search = RandomizedSearchCV(rf_base, rf_params, n_iter=5, cv=3, verbose=1, n_jobs=-1)\n",
        "print(\"Tuning hyperparameters...\")\n",
        "rf_search.fit(X_train_flat, y_train)\n",
        "best_rf_params = rf_search.best_params_\n",
        "print(f\"Best RF Params: {best_rf_params}\")\n",
        "\n",
        "# Step B: Train with Logging & Early Stopping (Warm Start)\n",
        "print(\"\\nTraining final RF with incremental logging...\")\n",
        "rf_final = RandomForestClassifier(\n",
        "    n_estimators=0, # Start at 0\n",
        "    warm_start=True, # Allows adding trees\n",
        "    random_state=42,\n",
        "    **best_rf_params\n",
        ")\n",
        "\n",
        "max_estimators = 200\n",
        "step = 10\n",
        "patience = 3\n",
        "best_val_score = 0\n",
        "no_improve_count = 0\n",
        "\n",
        "for i in range(step, max_estimators + 1, step):\n",
        "    rf_final.n_estimators = i\n",
        "    rf_final.fit(X_train_flat, y_train)\n",
        "\n",
        "    # Manual Validation Check\n",
        "    val_score = rf_final.score(X_test_flat, y_test) # Using Test as Val for demo visibility\n",
        "    print(f\" - Trees: {i}, Val Acc: {val_score:.4f}\")\n",
        "\n",
        "    if val_score > best_val_score + 0.0005: # Threshold\n",
        "        best_val_score = val_score\n",
        "        no_improve_count = 0\n",
        "    else:\n",
        "        no_improve_count += 1\n",
        "\n",
        "    if no_improve_count >= patience:\n",
        "        print(f\"Early stopping triggered at {i} trees.\")\n",
        "        break\n",
        "\n",
        "save_model_safely(rf_final, 'rf_model', 'sklearn', input_shape=46)\n",
        "\n",
        "\n",
        "# ==================================================================================\n",
        "# 2. XGBoost (Native Early Stopping)\n",
        "# ==================================================================================\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"2. XGBoost\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "# Step A: Tuning\n",
        "xgb_params = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'subsample': [0.7, 0.9]\n",
        "}\n",
        "xgb_base = xgb.XGBClassifier(objective='multi:softmax', num_class=12, n_estimators=50)\n",
        "xgb_search = RandomizedSearchCV(xgb_base, xgb_params, n_iter=5, cv=3, verbose=1, n_jobs=-1)\n",
        "print(\"Tuning hyperparameters...\")\n",
        "xgb_search.fit(X_train_flat, y_train)\n",
        "best_xgb_params = xgb_search.best_params_\n",
        "print(f\"Best XGB Params: {best_xgb_params}\")\n",
        "\n",
        "# Step B: Final Train with Early Stopping\n",
        "print(\"\\nTraining final XGB with native logs...\")\n",
        "xgb_final = xgb.XGBClassifier(\n",
        "    n_estimators=500, # High number, let ES stop it\n",
        "    objective='multi:softmax',\n",
        "    num_class=12,\n",
        "    **best_xgb_params\n",
        ")\n",
        "\n",
        "xgb_final.fit(\n",
        "    X_train_flat, y_train,\n",
        "    eval_set=[(X_train_flat, y_train), (X_test_flat, y_test)],\n",
        "    verbose=True # Prints log every epoch\n",
        ")\n",
        "\n",
        "save_model_safely(xgb_final, 'xgb_model', 'xgboost', input_shape=46)\n",
        "\n",
        "\n",
        "# ==================================================================================\n",
        "# 3. LSTM (Deep Learning)\n",
        "# ==================================================================================\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"3. LSTM\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "def build_lstm(units=64, dropout=0.2, lr=0.001):\n",
        "    m = keras.Sequential([\n",
        "        layers.Input(shape=input_shape_dl),\n",
        "        layers.LSTM(units, return_sequences=True),\n",
        "        layers.Dropout(dropout),\n",
        "        layers.LSTM(units // 2),\n",
        "        layers.Dense(12, activation='softmax')\n",
        "    ])\n",
        "    m.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return m\n",
        "\n",
        "# Tuning\n",
        "lstm_grid = {'units': [32, 64], 'dropout': [0.2, 0.4], 'lr': [0.01, 0.001]}\n",
        "lstm_final, _ = run_dl_random_search(build_lstm, lstm_grid, n_iter=3)\n",
        "\n",
        "# Final Training with Callbacks\n",
        "print(\"Training final LSTM...\")\n",
        "callbacks_list = [\n",
        "    callbacks.EarlyStopping(patience=5, restore_best_weights=True, verbose=1),\n",
        "    callbacks.ReduceLROnPlateau(factor=0.5, patience=3, verbose=1)\n",
        "]\n",
        "lstm_final.fit(X_train, y_train_cat, epochs=50, batch_size=64,\n",
        "               validation_split=0.1, callbacks=callbacks_list, verbose=1)\n",
        "\n",
        "save_model_safely(lstm_final, 'lstm_model', 'keras', input_shape=input_shape_dl)\n",
        "\n",
        "\n",
        "# ==================================================================================\n",
        "# 4. CNN\n",
        "# ==================================================================================\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"4. CNN\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "def build_cnn(filters=64, kernel_size=3, lr=0.001):\n",
        "    m = keras.Sequential([\n",
        "        layers.Input(shape=input_shape_dl),\n",
        "        layers.Conv1D(filters, kernel_size, activation='relu'),\n",
        "        layers.MaxPooling1D(2),\n",
        "        layers.Conv1D(filters*2, kernel_size, activation='relu'),\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "        layers.Dense(12, activation='softmax')\n",
        "    ])\n",
        "    m.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return m\n",
        "\n",
        "# Tuning\n",
        "cnn_grid = {'filters': [32, 64], 'kernel_size': [3, 5], 'lr': [0.001]}\n",
        "cnn_final, _ = run_dl_random_search(build_cnn, cnn_grid, n_iter=3)\n",
        "\n",
        "# Final Train\n",
        "print(\"Training final CNN...\")\n",
        "cnn_final.fit(X_train, y_train_cat, epochs=50, batch_size=64,\n",
        "              validation_split=0.1, callbacks=callbacks_list, verbose=1)\n",
        "\n",
        "save_model_safely(cnn_final, 'cnn_model', 'keras', input_shape=input_shape_dl)\n",
        "\n",
        "\n",
        "# ==================================================================================\n",
        "# 5. Transformer\n",
        "# ==================================================================================\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"5. Transformer\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    res = x + inputs\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    return x + res\n",
        "\n",
        "def build_transformer(head_size=64, num_heads=2, dropout=0.1, lr=0.001):\n",
        "    inputs = keras.Input(shape=input_shape_dl)\n",
        "    x = inputs\n",
        "    x = transformer_encoder(x, head_size, num_heads, 64, dropout)\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Dense(64, activation=\"relu\")(x)\n",
        "    outputs = layers.Dense(12, activation=\"softmax\")(x)\n",
        "\n",
        "    m = keras.Model(inputs, outputs)\n",
        "    m.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
        "              loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return m\n",
        "\n",
        "# Tuning\n",
        "trans_grid = {'head_size': [64], 'num_heads': [2, 4], 'dropout': [0.1], 'lr': [0.001, 0.0001]}\n",
        "trans_final, _ = run_dl_random_search(build_transformer, trans_grid, n_iter=3)\n",
        "\n",
        "# Final Train\n",
        "print(\"Training final Transformer...\")\n",
        "trans_final.fit(X_train, y_train_cat, epochs=50, batch_size=64,\n",
        "                validation_split=0.1, callbacks=callbacks_list, verbose=1)\n",
        "\n",
        "save_model_safely(trans_final, 'transformer_model', 'keras', input_shape=input_shape_dl)\n",
        "\n",
        "print(\"\\nAll models trained, tuned, and saved successfully.\")"
      ],
      "metadata": {
        "id": "K600Hgpyt4gu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bc4a893-c1e6-4010-aa71-e7f250e9e375"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "\n",
            "========================================\n",
            "1. Random Forest\n",
            "========================================\n",
            "Tuning hyperparameters...\n",
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
            "Best RF Params: {'min_samples_split': 2, 'max_features': 'sqrt', 'max_depth': 10}\n",
            "\n",
            "Training final RF with incremental logging...\n",
            " - Trees: 10, Val Acc: 0.9920\n",
            " - Trees: 20, Val Acc: 0.9934\n",
            " - Trees: 30, Val Acc: 0.9942\n",
            " - Trees: 40, Val Acc: 0.9920\n",
            " - Trees: 50, Val Acc: 0.9934\n",
            " - Trees: 60, Val Acc: 0.9934\n",
            "Early stopping triggered at 60 trees.\n",
            "Saving rf_model...\n",
            " - Native saved: rf_model\n",
            "\n",
            "========================================\n",
            "2. XGBoost\n",
            "========================================\n",
            "Tuning hyperparameters...\n",
            "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
            "Best XGB Params: {'subsample': 0.7, 'max_depth': 3, 'learning_rate': 0.1}\n",
            "\n",
            "Training final XGB with native logs...\n",
            "[0]\tvalidation_0-mlogloss:1.98707\tvalidation_1-mlogloss:1.99041\n",
            "[1]\tvalidation_0-mlogloss:1.68085\tvalidation_1-mlogloss:1.68557\n",
            "[2]\tvalidation_0-mlogloss:1.45609\tvalidation_1-mlogloss:1.46524\n",
            "[3]\tvalidation_0-mlogloss:1.28017\tvalidation_1-mlogloss:1.29251\n",
            "[4]\tvalidation_0-mlogloss:1.13505\tvalidation_1-mlogloss:1.14938\n",
            "[5]\tvalidation_0-mlogloss:1.01328\tvalidation_1-mlogloss:1.02876\n",
            "[6]\tvalidation_0-mlogloss:0.90983\tvalidation_1-mlogloss:0.92730\n",
            "[7]\tvalidation_0-mlogloss:0.82042\tvalidation_1-mlogloss:0.83866\n",
            "[8]\tvalidation_0-mlogloss:0.74136\tvalidation_1-mlogloss:0.76079\n",
            "[9]\tvalidation_0-mlogloss:0.67225\tvalidation_1-mlogloss:0.69277\n",
            "[10]\tvalidation_0-mlogloss:0.61102\tvalidation_1-mlogloss:0.63235\n",
            "[11]\tvalidation_0-mlogloss:0.55649\tvalidation_1-mlogloss:0.57831\n",
            "[12]\tvalidation_0-mlogloss:0.50698\tvalidation_1-mlogloss:0.52942\n",
            "[13]\tvalidation_0-mlogloss:0.46278\tvalidation_1-mlogloss:0.48619\n",
            "[14]\tvalidation_0-mlogloss:0.42251\tvalidation_1-mlogloss:0.44671\n",
            "[15]\tvalidation_0-mlogloss:0.38650\tvalidation_1-mlogloss:0.41129\n",
            "[16]\tvalidation_0-mlogloss:0.35383\tvalidation_1-mlogloss:0.37881\n",
            "[17]\tvalidation_0-mlogloss:0.32351\tvalidation_1-mlogloss:0.34864\n",
            "[18]\tvalidation_0-mlogloss:0.29574\tvalidation_1-mlogloss:0.32115\n",
            "[19]\tvalidation_0-mlogloss:0.27114\tvalidation_1-mlogloss:0.29707\n",
            "[20]\tvalidation_0-mlogloss:0.24880\tvalidation_1-mlogloss:0.27477\n",
            "[21]\tvalidation_0-mlogloss:0.22815\tvalidation_1-mlogloss:0.25440\n",
            "[22]\tvalidation_0-mlogloss:0.20948\tvalidation_1-mlogloss:0.23591\n",
            "[23]\tvalidation_0-mlogloss:0.19273\tvalidation_1-mlogloss:0.21928\n",
            "[24]\tvalidation_0-mlogloss:0.17704\tvalidation_1-mlogloss:0.20349\n",
            "[25]\tvalidation_0-mlogloss:0.16287\tvalidation_1-mlogloss:0.18929\n",
            "[26]\tvalidation_0-mlogloss:0.15010\tvalidation_1-mlogloss:0.17688\n",
            "[27]\tvalidation_0-mlogloss:0.13819\tvalidation_1-mlogloss:0.16480\n",
            "[28]\tvalidation_0-mlogloss:0.12750\tvalidation_1-mlogloss:0.15406\n",
            "[29]\tvalidation_0-mlogloss:0.11769\tvalidation_1-mlogloss:0.14425\n",
            "[30]\tvalidation_0-mlogloss:0.10858\tvalidation_1-mlogloss:0.13518\n",
            "[31]\tvalidation_0-mlogloss:0.09986\tvalidation_1-mlogloss:0.12651\n",
            "[32]\tvalidation_0-mlogloss:0.09245\tvalidation_1-mlogloss:0.11907\n",
            "[33]\tvalidation_0-mlogloss:0.08554\tvalidation_1-mlogloss:0.11214\n",
            "[34]\tvalidation_0-mlogloss:0.07912\tvalidation_1-mlogloss:0.10551\n",
            "[35]\tvalidation_0-mlogloss:0.07326\tvalidation_1-mlogloss:0.09948\n",
            "[36]\tvalidation_0-mlogloss:0.06794\tvalidation_1-mlogloss:0.09406\n",
            "[37]\tvalidation_0-mlogloss:0.06311\tvalidation_1-mlogloss:0.08903\n",
            "[38]\tvalidation_0-mlogloss:0.05871\tvalidation_1-mlogloss:0.08469\n",
            "[39]\tvalidation_0-mlogloss:0.05475\tvalidation_1-mlogloss:0.08066\n",
            "[40]\tvalidation_0-mlogloss:0.05102\tvalidation_1-mlogloss:0.07676\n",
            "[41]\tvalidation_0-mlogloss:0.04750\tvalidation_1-mlogloss:0.07334\n",
            "[42]\tvalidation_0-mlogloss:0.04425\tvalidation_1-mlogloss:0.07001\n",
            "[43]\tvalidation_0-mlogloss:0.04122\tvalidation_1-mlogloss:0.06676\n",
            "[44]\tvalidation_0-mlogloss:0.03853\tvalidation_1-mlogloss:0.06396\n",
            "[45]\tvalidation_0-mlogloss:0.03602\tvalidation_1-mlogloss:0.06150\n",
            "[46]\tvalidation_0-mlogloss:0.03379\tvalidation_1-mlogloss:0.05927\n",
            "[47]\tvalidation_0-mlogloss:0.03164\tvalidation_1-mlogloss:0.05688\n",
            "[48]\tvalidation_0-mlogloss:0.02966\tvalidation_1-mlogloss:0.05485\n",
            "[49]\tvalidation_0-mlogloss:0.02774\tvalidation_1-mlogloss:0.05292\n",
            "[50]\tvalidation_0-mlogloss:0.02601\tvalidation_1-mlogloss:0.05120\n",
            "[51]\tvalidation_0-mlogloss:0.02443\tvalidation_1-mlogloss:0.04980\n",
            "[52]\tvalidation_0-mlogloss:0.02298\tvalidation_1-mlogloss:0.04828\n",
            "[53]\tvalidation_0-mlogloss:0.02168\tvalidation_1-mlogloss:0.04706\n",
            "[54]\tvalidation_0-mlogloss:0.02040\tvalidation_1-mlogloss:0.04567\n",
            "[55]\tvalidation_0-mlogloss:0.01925\tvalidation_1-mlogloss:0.04460\n",
            "[56]\tvalidation_0-mlogloss:0.01816\tvalidation_1-mlogloss:0.04341\n",
            "[57]\tvalidation_0-mlogloss:0.01723\tvalidation_1-mlogloss:0.04251\n",
            "[58]\tvalidation_0-mlogloss:0.01635\tvalidation_1-mlogloss:0.04162\n",
            "[59]\tvalidation_0-mlogloss:0.01552\tvalidation_1-mlogloss:0.04082\n",
            "[60]\tvalidation_0-mlogloss:0.01477\tvalidation_1-mlogloss:0.04017\n",
            "[61]\tvalidation_0-mlogloss:0.01403\tvalidation_1-mlogloss:0.03922\n",
            "[62]\tvalidation_0-mlogloss:0.01341\tvalidation_1-mlogloss:0.03844\n",
            "[63]\tvalidation_0-mlogloss:0.01278\tvalidation_1-mlogloss:0.03778\n",
            "[64]\tvalidation_0-mlogloss:0.01212\tvalidation_1-mlogloss:0.03724\n",
            "[65]\tvalidation_0-mlogloss:0.01156\tvalidation_1-mlogloss:0.03657\n",
            "[66]\tvalidation_0-mlogloss:0.01104\tvalidation_1-mlogloss:0.03601\n",
            "[67]\tvalidation_0-mlogloss:0.01058\tvalidation_1-mlogloss:0.03556\n",
            "[68]\tvalidation_0-mlogloss:0.01013\tvalidation_1-mlogloss:0.03501\n",
            "[69]\tvalidation_0-mlogloss:0.00971\tvalidation_1-mlogloss:0.03457\n",
            "[70]\tvalidation_0-mlogloss:0.00932\tvalidation_1-mlogloss:0.03417\n",
            "[71]\tvalidation_0-mlogloss:0.00892\tvalidation_1-mlogloss:0.03384\n",
            "[72]\tvalidation_0-mlogloss:0.00860\tvalidation_1-mlogloss:0.03359\n",
            "[73]\tvalidation_0-mlogloss:0.00830\tvalidation_1-mlogloss:0.03321\n",
            "[74]\tvalidation_0-mlogloss:0.00798\tvalidation_1-mlogloss:0.03298\n",
            "[75]\tvalidation_0-mlogloss:0.00768\tvalidation_1-mlogloss:0.03276\n",
            "[76]\tvalidation_0-mlogloss:0.00738\tvalidation_1-mlogloss:0.03256\n",
            "[77]\tvalidation_0-mlogloss:0.00714\tvalidation_1-mlogloss:0.03227\n",
            "[78]\tvalidation_0-mlogloss:0.00686\tvalidation_1-mlogloss:0.03201\n",
            "[79]\tvalidation_0-mlogloss:0.00663\tvalidation_1-mlogloss:0.03174\n",
            "[80]\tvalidation_0-mlogloss:0.00640\tvalidation_1-mlogloss:0.03165\n",
            "[81]\tvalidation_0-mlogloss:0.00620\tvalidation_1-mlogloss:0.03142\n",
            "[82]\tvalidation_0-mlogloss:0.00602\tvalidation_1-mlogloss:0.03123\n",
            "[83]\tvalidation_0-mlogloss:0.00583\tvalidation_1-mlogloss:0.03105\n",
            "[84]\tvalidation_0-mlogloss:0.00567\tvalidation_1-mlogloss:0.03085\n",
            "[85]\tvalidation_0-mlogloss:0.00550\tvalidation_1-mlogloss:0.03072\n",
            "[86]\tvalidation_0-mlogloss:0.00533\tvalidation_1-mlogloss:0.03060\n",
            "[87]\tvalidation_0-mlogloss:0.00517\tvalidation_1-mlogloss:0.03043\n",
            "[88]\tvalidation_0-mlogloss:0.00503\tvalidation_1-mlogloss:0.03032\n",
            "[89]\tvalidation_0-mlogloss:0.00490\tvalidation_1-mlogloss:0.03009\n",
            "[90]\tvalidation_0-mlogloss:0.00477\tvalidation_1-mlogloss:0.03004\n",
            "[91]\tvalidation_0-mlogloss:0.00465\tvalidation_1-mlogloss:0.02991\n",
            "[92]\tvalidation_0-mlogloss:0.00453\tvalidation_1-mlogloss:0.02967\n",
            "[93]\tvalidation_0-mlogloss:0.00442\tvalidation_1-mlogloss:0.02952\n",
            "[94]\tvalidation_0-mlogloss:0.00433\tvalidation_1-mlogloss:0.02940\n",
            "[95]\tvalidation_0-mlogloss:0.00423\tvalidation_1-mlogloss:0.02926\n",
            "[96]\tvalidation_0-mlogloss:0.00413\tvalidation_1-mlogloss:0.02912\n",
            "[97]\tvalidation_0-mlogloss:0.00404\tvalidation_1-mlogloss:0.02902\n",
            "[98]\tvalidation_0-mlogloss:0.00396\tvalidation_1-mlogloss:0.02894\n",
            "[99]\tvalidation_0-mlogloss:0.00387\tvalidation_1-mlogloss:0.02881\n",
            "[100]\tvalidation_0-mlogloss:0.00378\tvalidation_1-mlogloss:0.02874\n",
            "[101]\tvalidation_0-mlogloss:0.00371\tvalidation_1-mlogloss:0.02870\n",
            "[102]\tvalidation_0-mlogloss:0.00362\tvalidation_1-mlogloss:0.02854\n",
            "[103]\tvalidation_0-mlogloss:0.00356\tvalidation_1-mlogloss:0.02851\n",
            "[104]\tvalidation_0-mlogloss:0.00350\tvalidation_1-mlogloss:0.02841\n",
            "[105]\tvalidation_0-mlogloss:0.00344\tvalidation_1-mlogloss:0.02843\n",
            "[106]\tvalidation_0-mlogloss:0.00338\tvalidation_1-mlogloss:0.02842\n",
            "[107]\tvalidation_0-mlogloss:0.00332\tvalidation_1-mlogloss:0.02831\n",
            "[108]\tvalidation_0-mlogloss:0.00325\tvalidation_1-mlogloss:0.02821\n",
            "[109]\tvalidation_0-mlogloss:0.00320\tvalidation_1-mlogloss:0.02824\n",
            "[110]\tvalidation_0-mlogloss:0.00315\tvalidation_1-mlogloss:0.02808\n",
            "[111]\tvalidation_0-mlogloss:0.00310\tvalidation_1-mlogloss:0.02792\n",
            "[112]\tvalidation_0-mlogloss:0.00305\tvalidation_1-mlogloss:0.02778\n",
            "[113]\tvalidation_0-mlogloss:0.00301\tvalidation_1-mlogloss:0.02773\n",
            "[114]\tvalidation_0-mlogloss:0.00297\tvalidation_1-mlogloss:0.02768\n",
            "[115]\tvalidation_0-mlogloss:0.00292\tvalidation_1-mlogloss:0.02755\n",
            "[116]\tvalidation_0-mlogloss:0.00288\tvalidation_1-mlogloss:0.02747\n",
            "[117]\tvalidation_0-mlogloss:0.00284\tvalidation_1-mlogloss:0.02741\n",
            "[118]\tvalidation_0-mlogloss:0.00280\tvalidation_1-mlogloss:0.02737\n",
            "[119]\tvalidation_0-mlogloss:0.00276\tvalidation_1-mlogloss:0.02732\n",
            "[120]\tvalidation_0-mlogloss:0.00273\tvalidation_1-mlogloss:0.02729\n",
            "[121]\tvalidation_0-mlogloss:0.00269\tvalidation_1-mlogloss:0.02717\n",
            "[122]\tvalidation_0-mlogloss:0.00266\tvalidation_1-mlogloss:0.02712\n",
            "[123]\tvalidation_0-mlogloss:0.00263\tvalidation_1-mlogloss:0.02712\n",
            "[124]\tvalidation_0-mlogloss:0.00260\tvalidation_1-mlogloss:0.02711\n",
            "[125]\tvalidation_0-mlogloss:0.00257\tvalidation_1-mlogloss:0.02698\n",
            "[126]\tvalidation_0-mlogloss:0.00254\tvalidation_1-mlogloss:0.02691\n",
            "[127]\tvalidation_0-mlogloss:0.00252\tvalidation_1-mlogloss:0.02683\n",
            "[128]\tvalidation_0-mlogloss:0.00249\tvalidation_1-mlogloss:0.02673\n",
            "[129]\tvalidation_0-mlogloss:0.00246\tvalidation_1-mlogloss:0.02667\n",
            "[130]\tvalidation_0-mlogloss:0.00244\tvalidation_1-mlogloss:0.02666\n",
            "[131]\tvalidation_0-mlogloss:0.00242\tvalidation_1-mlogloss:0.02655\n",
            "[132]\tvalidation_0-mlogloss:0.00240\tvalidation_1-mlogloss:0.02645\n",
            "[133]\tvalidation_0-mlogloss:0.00238\tvalidation_1-mlogloss:0.02640\n",
            "[134]\tvalidation_0-mlogloss:0.00236\tvalidation_1-mlogloss:0.02638\n",
            "[135]\tvalidation_0-mlogloss:0.00233\tvalidation_1-mlogloss:0.02628\n",
            "[136]\tvalidation_0-mlogloss:0.00232\tvalidation_1-mlogloss:0.02626\n",
            "[137]\tvalidation_0-mlogloss:0.00230\tvalidation_1-mlogloss:0.02618\n",
            "[138]\tvalidation_0-mlogloss:0.00229\tvalidation_1-mlogloss:0.02610\n",
            "[139]\tvalidation_0-mlogloss:0.00227\tvalidation_1-mlogloss:0.02618\n",
            "[140]\tvalidation_0-mlogloss:0.00225\tvalidation_1-mlogloss:0.02610\n",
            "[141]\tvalidation_0-mlogloss:0.00224\tvalidation_1-mlogloss:0.02606\n",
            "[142]\tvalidation_0-mlogloss:0.00222\tvalidation_1-mlogloss:0.02601\n",
            "[143]\tvalidation_0-mlogloss:0.00221\tvalidation_1-mlogloss:0.02598\n",
            "[144]\tvalidation_0-mlogloss:0.00219\tvalidation_1-mlogloss:0.02594\n",
            "[145]\tvalidation_0-mlogloss:0.00218\tvalidation_1-mlogloss:0.02589\n",
            "[146]\tvalidation_0-mlogloss:0.00216\tvalidation_1-mlogloss:0.02584\n",
            "[147]\tvalidation_0-mlogloss:0.00215\tvalidation_1-mlogloss:0.02586\n",
            "[148]\tvalidation_0-mlogloss:0.00213\tvalidation_1-mlogloss:0.02583\n",
            "[149]\tvalidation_0-mlogloss:0.00212\tvalidation_1-mlogloss:0.02575\n",
            "[150]\tvalidation_0-mlogloss:0.00211\tvalidation_1-mlogloss:0.02574\n",
            "[151]\tvalidation_0-mlogloss:0.00210\tvalidation_1-mlogloss:0.02573\n",
            "[152]\tvalidation_0-mlogloss:0.00209\tvalidation_1-mlogloss:0.02571\n",
            "[153]\tvalidation_0-mlogloss:0.00208\tvalidation_1-mlogloss:0.02569\n",
            "[154]\tvalidation_0-mlogloss:0.00206\tvalidation_1-mlogloss:0.02565\n",
            "[155]\tvalidation_0-mlogloss:0.00205\tvalidation_1-mlogloss:0.02562\n",
            "[156]\tvalidation_0-mlogloss:0.00204\tvalidation_1-mlogloss:0.02557\n",
            "[157]\tvalidation_0-mlogloss:0.00203\tvalidation_1-mlogloss:0.02558\n",
            "[158]\tvalidation_0-mlogloss:0.00202\tvalidation_1-mlogloss:0.02553\n",
            "[159]\tvalidation_0-mlogloss:0.00201\tvalidation_1-mlogloss:0.02551\n",
            "[160]\tvalidation_0-mlogloss:0.00200\tvalidation_1-mlogloss:0.02550\n",
            "[161]\tvalidation_0-mlogloss:0.00199\tvalidation_1-mlogloss:0.02550\n",
            "[162]\tvalidation_0-mlogloss:0.00199\tvalidation_1-mlogloss:0.02544\n",
            "[163]\tvalidation_0-mlogloss:0.00198\tvalidation_1-mlogloss:0.02543\n",
            "[164]\tvalidation_0-mlogloss:0.00197\tvalidation_1-mlogloss:0.02536\n",
            "[165]\tvalidation_0-mlogloss:0.00196\tvalidation_1-mlogloss:0.02532\n",
            "[166]\tvalidation_0-mlogloss:0.00195\tvalidation_1-mlogloss:0.02531\n",
            "[167]\tvalidation_0-mlogloss:0.00194\tvalidation_1-mlogloss:0.02534\n",
            "[168]\tvalidation_0-mlogloss:0.00193\tvalidation_1-mlogloss:0.02534\n",
            "[169]\tvalidation_0-mlogloss:0.00193\tvalidation_1-mlogloss:0.02533\n",
            "[170]\tvalidation_0-mlogloss:0.00192\tvalidation_1-mlogloss:0.02537\n",
            "[171]\tvalidation_0-mlogloss:0.00191\tvalidation_1-mlogloss:0.02530\n",
            "[172]\tvalidation_0-mlogloss:0.00190\tvalidation_1-mlogloss:0.02525\n",
            "[173]\tvalidation_0-mlogloss:0.00189\tvalidation_1-mlogloss:0.02523\n",
            "[174]\tvalidation_0-mlogloss:0.00189\tvalidation_1-mlogloss:0.02525\n",
            "[175]\tvalidation_0-mlogloss:0.00188\tvalidation_1-mlogloss:0.02523\n",
            "[176]\tvalidation_0-mlogloss:0.00187\tvalidation_1-mlogloss:0.02523\n",
            "[177]\tvalidation_0-mlogloss:0.00187\tvalidation_1-mlogloss:0.02520\n",
            "[178]\tvalidation_0-mlogloss:0.00186\tvalidation_1-mlogloss:0.02518\n",
            "[179]\tvalidation_0-mlogloss:0.00185\tvalidation_1-mlogloss:0.02519\n",
            "[180]\tvalidation_0-mlogloss:0.00184\tvalidation_1-mlogloss:0.02517\n",
            "[181]\tvalidation_0-mlogloss:0.00184\tvalidation_1-mlogloss:0.02514\n",
            "[182]\tvalidation_0-mlogloss:0.00183\tvalidation_1-mlogloss:0.02511\n",
            "[183]\tvalidation_0-mlogloss:0.00183\tvalidation_1-mlogloss:0.02509\n",
            "[184]\tvalidation_0-mlogloss:0.00182\tvalidation_1-mlogloss:0.02513\n",
            "[185]\tvalidation_0-mlogloss:0.00182\tvalidation_1-mlogloss:0.02511\n",
            "[186]\tvalidation_0-mlogloss:0.00181\tvalidation_1-mlogloss:0.02506\n",
            "[187]\tvalidation_0-mlogloss:0.00180\tvalidation_1-mlogloss:0.02503\n",
            "[188]\tvalidation_0-mlogloss:0.00180\tvalidation_1-mlogloss:0.02501\n",
            "[189]\tvalidation_0-mlogloss:0.00179\tvalidation_1-mlogloss:0.02501\n",
            "[190]\tvalidation_0-mlogloss:0.00179\tvalidation_1-mlogloss:0.02498\n",
            "[191]\tvalidation_0-mlogloss:0.00178\tvalidation_1-mlogloss:0.02498\n",
            "[192]\tvalidation_0-mlogloss:0.00177\tvalidation_1-mlogloss:0.02498\n",
            "[193]\tvalidation_0-mlogloss:0.00177\tvalidation_1-mlogloss:0.02495\n",
            "[194]\tvalidation_0-mlogloss:0.00176\tvalidation_1-mlogloss:0.02496\n",
            "[195]\tvalidation_0-mlogloss:0.00176\tvalidation_1-mlogloss:0.02495\n",
            "[196]\tvalidation_0-mlogloss:0.00175\tvalidation_1-mlogloss:0.02493\n",
            "[197]\tvalidation_0-mlogloss:0.00175\tvalidation_1-mlogloss:0.02493\n",
            "[198]\tvalidation_0-mlogloss:0.00174\tvalidation_1-mlogloss:0.02491\n",
            "[199]\tvalidation_0-mlogloss:0.00174\tvalidation_1-mlogloss:0.02489\n",
            "[200]\tvalidation_0-mlogloss:0.00173\tvalidation_1-mlogloss:0.02489\n",
            "[201]\tvalidation_0-mlogloss:0.00173\tvalidation_1-mlogloss:0.02489\n",
            "[202]\tvalidation_0-mlogloss:0.00172\tvalidation_1-mlogloss:0.02489\n",
            "[203]\tvalidation_0-mlogloss:0.00172\tvalidation_1-mlogloss:0.02486\n",
            "[204]\tvalidation_0-mlogloss:0.00171\tvalidation_1-mlogloss:0.02483\n",
            "[205]\tvalidation_0-mlogloss:0.00171\tvalidation_1-mlogloss:0.02482\n",
            "[206]\tvalidation_0-mlogloss:0.00170\tvalidation_1-mlogloss:0.02480\n",
            "[207]\tvalidation_0-mlogloss:0.00170\tvalidation_1-mlogloss:0.02482\n",
            "[208]\tvalidation_0-mlogloss:0.00170\tvalidation_1-mlogloss:0.02487\n",
            "[209]\tvalidation_0-mlogloss:0.00169\tvalidation_1-mlogloss:0.02487\n",
            "[210]\tvalidation_0-mlogloss:0.00169\tvalidation_1-mlogloss:0.02485\n",
            "[211]\tvalidation_0-mlogloss:0.00168\tvalidation_1-mlogloss:0.02483\n",
            "[212]\tvalidation_0-mlogloss:0.00168\tvalidation_1-mlogloss:0.02485\n",
            "[213]\tvalidation_0-mlogloss:0.00167\tvalidation_1-mlogloss:0.02485\n",
            "[214]\tvalidation_0-mlogloss:0.00167\tvalidation_1-mlogloss:0.02484\n",
            "[215]\tvalidation_0-mlogloss:0.00167\tvalidation_1-mlogloss:0.02482\n",
            "[216]\tvalidation_0-mlogloss:0.00166\tvalidation_1-mlogloss:0.02481\n",
            "[217]\tvalidation_0-mlogloss:0.00166\tvalidation_1-mlogloss:0.02476\n",
            "[218]\tvalidation_0-mlogloss:0.00166\tvalidation_1-mlogloss:0.02472\n",
            "[219]\tvalidation_0-mlogloss:0.00165\tvalidation_1-mlogloss:0.02472\n",
            "[220]\tvalidation_0-mlogloss:0.00165\tvalidation_1-mlogloss:0.02474\n",
            "[221]\tvalidation_0-mlogloss:0.00165\tvalidation_1-mlogloss:0.02476\n",
            "[222]\tvalidation_0-mlogloss:0.00164\tvalidation_1-mlogloss:0.02475\n",
            "[223]\tvalidation_0-mlogloss:0.00164\tvalidation_1-mlogloss:0.02474\n",
            "[224]\tvalidation_0-mlogloss:0.00163\tvalidation_1-mlogloss:0.02469\n",
            "[225]\tvalidation_0-mlogloss:0.00163\tvalidation_1-mlogloss:0.02465\n",
            "[226]\tvalidation_0-mlogloss:0.00163\tvalidation_1-mlogloss:0.02464\n",
            "[227]\tvalidation_0-mlogloss:0.00162\tvalidation_1-mlogloss:0.02467\n",
            "[228]\tvalidation_0-mlogloss:0.00162\tvalidation_1-mlogloss:0.02469\n",
            "[229]\tvalidation_0-mlogloss:0.00161\tvalidation_1-mlogloss:0.02464\n",
            "[230]\tvalidation_0-mlogloss:0.00161\tvalidation_1-mlogloss:0.02460\n",
            "[231]\tvalidation_0-mlogloss:0.00161\tvalidation_1-mlogloss:0.02456\n",
            "[232]\tvalidation_0-mlogloss:0.00161\tvalidation_1-mlogloss:0.02457\n",
            "[233]\tvalidation_0-mlogloss:0.00160\tvalidation_1-mlogloss:0.02458\n",
            "[234]\tvalidation_0-mlogloss:0.00160\tvalidation_1-mlogloss:0.02454\n",
            "[235]\tvalidation_0-mlogloss:0.00160\tvalidation_1-mlogloss:0.02456\n",
            "[236]\tvalidation_0-mlogloss:0.00159\tvalidation_1-mlogloss:0.02454\n",
            "[237]\tvalidation_0-mlogloss:0.00159\tvalidation_1-mlogloss:0.02453\n",
            "[238]\tvalidation_0-mlogloss:0.00159\tvalidation_1-mlogloss:0.02451\n",
            "[239]\tvalidation_0-mlogloss:0.00158\tvalidation_1-mlogloss:0.02449\n",
            "[240]\tvalidation_0-mlogloss:0.00158\tvalidation_1-mlogloss:0.02448\n",
            "[241]\tvalidation_0-mlogloss:0.00158\tvalidation_1-mlogloss:0.02449\n",
            "[242]\tvalidation_0-mlogloss:0.00158\tvalidation_1-mlogloss:0.02449\n",
            "[243]\tvalidation_0-mlogloss:0.00157\tvalidation_1-mlogloss:0.02447\n",
            "[244]\tvalidation_0-mlogloss:0.00157\tvalidation_1-mlogloss:0.02448\n",
            "[245]\tvalidation_0-mlogloss:0.00156\tvalidation_1-mlogloss:0.02448\n",
            "[246]\tvalidation_0-mlogloss:0.00156\tvalidation_1-mlogloss:0.02448\n",
            "[247]\tvalidation_0-mlogloss:0.00156\tvalidation_1-mlogloss:0.02447\n",
            "[248]\tvalidation_0-mlogloss:0.00156\tvalidation_1-mlogloss:0.02444\n",
            "[249]\tvalidation_0-mlogloss:0.00155\tvalidation_1-mlogloss:0.02443\n",
            "[250]\tvalidation_0-mlogloss:0.00155\tvalidation_1-mlogloss:0.02441\n",
            "[251]\tvalidation_0-mlogloss:0.00155\tvalidation_1-mlogloss:0.02441\n",
            "[252]\tvalidation_0-mlogloss:0.00155\tvalidation_1-mlogloss:0.02437\n",
            "[253]\tvalidation_0-mlogloss:0.00154\tvalidation_1-mlogloss:0.02437\n",
            "[254]\tvalidation_0-mlogloss:0.00154\tvalidation_1-mlogloss:0.02433\n",
            "[255]\tvalidation_0-mlogloss:0.00154\tvalidation_1-mlogloss:0.02436\n",
            "[256]\tvalidation_0-mlogloss:0.00154\tvalidation_1-mlogloss:0.02437\n",
            "[257]\tvalidation_0-mlogloss:0.00153\tvalidation_1-mlogloss:0.02438\n",
            "[258]\tvalidation_0-mlogloss:0.00153\tvalidation_1-mlogloss:0.02433\n",
            "[259]\tvalidation_0-mlogloss:0.00153\tvalidation_1-mlogloss:0.02429\n",
            "[260]\tvalidation_0-mlogloss:0.00153\tvalidation_1-mlogloss:0.02428\n",
            "[261]\tvalidation_0-mlogloss:0.00152\tvalidation_1-mlogloss:0.02426\n",
            "[262]\tvalidation_0-mlogloss:0.00152\tvalidation_1-mlogloss:0.02422\n",
            "[263]\tvalidation_0-mlogloss:0.00152\tvalidation_1-mlogloss:0.02422\n",
            "[264]\tvalidation_0-mlogloss:0.00152\tvalidation_1-mlogloss:0.02420\n",
            "[265]\tvalidation_0-mlogloss:0.00151\tvalidation_1-mlogloss:0.02418\n",
            "[266]\tvalidation_0-mlogloss:0.00151\tvalidation_1-mlogloss:0.02413\n",
            "[267]\tvalidation_0-mlogloss:0.00151\tvalidation_1-mlogloss:0.02413\n",
            "[268]\tvalidation_0-mlogloss:0.00151\tvalidation_1-mlogloss:0.02411\n",
            "[269]\tvalidation_0-mlogloss:0.00150\tvalidation_1-mlogloss:0.02409\n",
            "[270]\tvalidation_0-mlogloss:0.00150\tvalidation_1-mlogloss:0.02406\n",
            "[271]\tvalidation_0-mlogloss:0.00150\tvalidation_1-mlogloss:0.02405\n",
            "[272]\tvalidation_0-mlogloss:0.00150\tvalidation_1-mlogloss:0.02406\n",
            "[273]\tvalidation_0-mlogloss:0.00150\tvalidation_1-mlogloss:0.02407\n",
            "[274]\tvalidation_0-mlogloss:0.00149\tvalidation_1-mlogloss:0.02405\n",
            "[275]\tvalidation_0-mlogloss:0.00149\tvalidation_1-mlogloss:0.02404\n",
            "[276]\tvalidation_0-mlogloss:0.00149\tvalidation_1-mlogloss:0.02402\n",
            "[277]\tvalidation_0-mlogloss:0.00149\tvalidation_1-mlogloss:0.02402\n",
            "[278]\tvalidation_0-mlogloss:0.00149\tvalidation_1-mlogloss:0.02404\n",
            "[279]\tvalidation_0-mlogloss:0.00148\tvalidation_1-mlogloss:0.02402\n",
            "[280]\tvalidation_0-mlogloss:0.00148\tvalidation_1-mlogloss:0.02399\n",
            "[281]\tvalidation_0-mlogloss:0.00148\tvalidation_1-mlogloss:0.02398\n",
            "[282]\tvalidation_0-mlogloss:0.00148\tvalidation_1-mlogloss:0.02396\n",
            "[283]\tvalidation_0-mlogloss:0.00148\tvalidation_1-mlogloss:0.02397\n",
            "[284]\tvalidation_0-mlogloss:0.00147\tvalidation_1-mlogloss:0.02394\n",
            "[285]\tvalidation_0-mlogloss:0.00147\tvalidation_1-mlogloss:0.02394\n",
            "[286]\tvalidation_0-mlogloss:0.00147\tvalidation_1-mlogloss:0.02397\n",
            "[287]\tvalidation_0-mlogloss:0.00147\tvalidation_1-mlogloss:0.02395\n",
            "[288]\tvalidation_0-mlogloss:0.00147\tvalidation_1-mlogloss:0.02396\n",
            "[289]\tvalidation_0-mlogloss:0.00147\tvalidation_1-mlogloss:0.02397\n",
            "[290]\tvalidation_0-mlogloss:0.00146\tvalidation_1-mlogloss:0.02394\n",
            "[291]\tvalidation_0-mlogloss:0.00146\tvalidation_1-mlogloss:0.02395\n",
            "[292]\tvalidation_0-mlogloss:0.00146\tvalidation_1-mlogloss:0.02397\n",
            "[293]\tvalidation_0-mlogloss:0.00146\tvalidation_1-mlogloss:0.02395\n",
            "[294]\tvalidation_0-mlogloss:0.00146\tvalidation_1-mlogloss:0.02396\n",
            "[295]\tvalidation_0-mlogloss:0.00145\tvalidation_1-mlogloss:0.02393\n",
            "[296]\tvalidation_0-mlogloss:0.00145\tvalidation_1-mlogloss:0.02393\n",
            "[297]\tvalidation_0-mlogloss:0.00145\tvalidation_1-mlogloss:0.02396\n",
            "[298]\tvalidation_0-mlogloss:0.00145\tvalidation_1-mlogloss:0.02397\n",
            "[299]\tvalidation_0-mlogloss:0.00145\tvalidation_1-mlogloss:0.02396\n",
            "[300]\tvalidation_0-mlogloss:0.00145\tvalidation_1-mlogloss:0.02392\n",
            "[301]\tvalidation_0-mlogloss:0.00144\tvalidation_1-mlogloss:0.02391\n",
            "[302]\tvalidation_0-mlogloss:0.00144\tvalidation_1-mlogloss:0.02392\n",
            "[303]\tvalidation_0-mlogloss:0.00144\tvalidation_1-mlogloss:0.02391\n",
            "[304]\tvalidation_0-mlogloss:0.00144\tvalidation_1-mlogloss:0.02389\n",
            "[305]\tvalidation_0-mlogloss:0.00144\tvalidation_1-mlogloss:0.02388\n",
            "[306]\tvalidation_0-mlogloss:0.00144\tvalidation_1-mlogloss:0.02387\n",
            "[307]\tvalidation_0-mlogloss:0.00144\tvalidation_1-mlogloss:0.02387\n",
            "[308]\tvalidation_0-mlogloss:0.00143\tvalidation_1-mlogloss:0.02388\n",
            "[309]\tvalidation_0-mlogloss:0.00143\tvalidation_1-mlogloss:0.02386\n",
            "[310]\tvalidation_0-mlogloss:0.00143\tvalidation_1-mlogloss:0.02387\n",
            "[311]\tvalidation_0-mlogloss:0.00143\tvalidation_1-mlogloss:0.02387\n",
            "[312]\tvalidation_0-mlogloss:0.00143\tvalidation_1-mlogloss:0.02387\n",
            "[313]\tvalidation_0-mlogloss:0.00143\tvalidation_1-mlogloss:0.02387\n",
            "[314]\tvalidation_0-mlogloss:0.00143\tvalidation_1-mlogloss:0.02388\n",
            "[315]\tvalidation_0-mlogloss:0.00142\tvalidation_1-mlogloss:0.02389\n",
            "[316]\tvalidation_0-mlogloss:0.00142\tvalidation_1-mlogloss:0.02387\n",
            "[317]\tvalidation_0-mlogloss:0.00142\tvalidation_1-mlogloss:0.02386\n",
            "[318]\tvalidation_0-mlogloss:0.00142\tvalidation_1-mlogloss:0.02386\n",
            "[319]\tvalidation_0-mlogloss:0.00142\tvalidation_1-mlogloss:0.02386\n",
            "[320]\tvalidation_0-mlogloss:0.00142\tvalidation_1-mlogloss:0.02385\n",
            "[321]\tvalidation_0-mlogloss:0.00142\tvalidation_1-mlogloss:0.02386\n",
            "[322]\tvalidation_0-mlogloss:0.00142\tvalidation_1-mlogloss:0.02387\n",
            "[323]\tvalidation_0-mlogloss:0.00141\tvalidation_1-mlogloss:0.02386\n",
            "[324]\tvalidation_0-mlogloss:0.00141\tvalidation_1-mlogloss:0.02386\n",
            "[325]\tvalidation_0-mlogloss:0.00141\tvalidation_1-mlogloss:0.02389\n",
            "[326]\tvalidation_0-mlogloss:0.00141\tvalidation_1-mlogloss:0.02387\n",
            "[327]\tvalidation_0-mlogloss:0.00141\tvalidation_1-mlogloss:0.02385\n",
            "[328]\tvalidation_0-mlogloss:0.00141\tvalidation_1-mlogloss:0.02384\n",
            "[329]\tvalidation_0-mlogloss:0.00141\tvalidation_1-mlogloss:0.02383\n",
            "[330]\tvalidation_0-mlogloss:0.00141\tvalidation_1-mlogloss:0.02383\n",
            "[331]\tvalidation_0-mlogloss:0.00141\tvalidation_1-mlogloss:0.02384\n",
            "[332]\tvalidation_0-mlogloss:0.00140\tvalidation_1-mlogloss:0.02384\n",
            "[333]\tvalidation_0-mlogloss:0.00140\tvalidation_1-mlogloss:0.02386\n",
            "[334]\tvalidation_0-mlogloss:0.00140\tvalidation_1-mlogloss:0.02388\n",
            "[335]\tvalidation_0-mlogloss:0.00140\tvalidation_1-mlogloss:0.02387\n",
            "[336]\tvalidation_0-mlogloss:0.00140\tvalidation_1-mlogloss:0.02387\n",
            "[337]\tvalidation_0-mlogloss:0.00140\tvalidation_1-mlogloss:0.02387\n",
            "[338]\tvalidation_0-mlogloss:0.00140\tvalidation_1-mlogloss:0.02386\n",
            "[339]\tvalidation_0-mlogloss:0.00140\tvalidation_1-mlogloss:0.02387\n",
            "[340]\tvalidation_0-mlogloss:0.00140\tvalidation_1-mlogloss:0.02388\n",
            "[341]\tvalidation_0-mlogloss:0.00140\tvalidation_1-mlogloss:0.02391\n",
            "[342]\tvalidation_0-mlogloss:0.00140\tvalidation_1-mlogloss:0.02390\n",
            "[343]\tvalidation_0-mlogloss:0.00139\tvalidation_1-mlogloss:0.02391\n",
            "[344]\tvalidation_0-mlogloss:0.00139\tvalidation_1-mlogloss:0.02392\n",
            "[345]\tvalidation_0-mlogloss:0.00139\tvalidation_1-mlogloss:0.02392\n",
            "[346]\tvalidation_0-mlogloss:0.00139\tvalidation_1-mlogloss:0.02393\n",
            "[347]\tvalidation_0-mlogloss:0.00139\tvalidation_1-mlogloss:0.02390\n",
            "[348]\tvalidation_0-mlogloss:0.00139\tvalidation_1-mlogloss:0.02388\n",
            "[349]\tvalidation_0-mlogloss:0.00139\tvalidation_1-mlogloss:0.02388\n",
            "[350]\tvalidation_0-mlogloss:0.00139\tvalidation_1-mlogloss:0.02389\n",
            "[351]\tvalidation_0-mlogloss:0.00139\tvalidation_1-mlogloss:0.02388\n",
            "[352]\tvalidation_0-mlogloss:0.00139\tvalidation_1-mlogloss:0.02390\n",
            "[353]\tvalidation_0-mlogloss:0.00138\tvalidation_1-mlogloss:0.02390\n",
            "[354]\tvalidation_0-mlogloss:0.00138\tvalidation_1-mlogloss:0.02385\n",
            "[355]\tvalidation_0-mlogloss:0.00138\tvalidation_1-mlogloss:0.02384\n",
            "[356]\tvalidation_0-mlogloss:0.00138\tvalidation_1-mlogloss:0.02384\n",
            "[357]\tvalidation_0-mlogloss:0.00138\tvalidation_1-mlogloss:0.02385\n",
            "[358]\tvalidation_0-mlogloss:0.00138\tvalidation_1-mlogloss:0.02386\n",
            "[359]\tvalidation_0-mlogloss:0.00138\tvalidation_1-mlogloss:0.02385\n",
            "[360]\tvalidation_0-mlogloss:0.00138\tvalidation_1-mlogloss:0.02383\n",
            "[361]\tvalidation_0-mlogloss:0.00138\tvalidation_1-mlogloss:0.02383\n",
            "[362]\tvalidation_0-mlogloss:0.00138\tvalidation_1-mlogloss:0.02380\n",
            "[363]\tvalidation_0-mlogloss:0.00138\tvalidation_1-mlogloss:0.02379\n",
            "[364]\tvalidation_0-mlogloss:0.00138\tvalidation_1-mlogloss:0.02379\n",
            "[365]\tvalidation_0-mlogloss:0.00137\tvalidation_1-mlogloss:0.02380\n",
            "[366]\tvalidation_0-mlogloss:0.00137\tvalidation_1-mlogloss:0.02378\n",
            "[367]\tvalidation_0-mlogloss:0.00137\tvalidation_1-mlogloss:0.02382\n",
            "[368]\tvalidation_0-mlogloss:0.00137\tvalidation_1-mlogloss:0.02381\n",
            "[369]\tvalidation_0-mlogloss:0.00137\tvalidation_1-mlogloss:0.02379\n",
            "[370]\tvalidation_0-mlogloss:0.00137\tvalidation_1-mlogloss:0.02379\n",
            "[371]\tvalidation_0-mlogloss:0.00137\tvalidation_1-mlogloss:0.02380\n",
            "[372]\tvalidation_0-mlogloss:0.00137\tvalidation_1-mlogloss:0.02380\n",
            "[373]\tvalidation_0-mlogloss:0.00137\tvalidation_1-mlogloss:0.02380\n",
            "[374]\tvalidation_0-mlogloss:0.00137\tvalidation_1-mlogloss:0.02379\n",
            "[375]\tvalidation_0-mlogloss:0.00137\tvalidation_1-mlogloss:0.02379\n",
            "[376]\tvalidation_0-mlogloss:0.00137\tvalidation_1-mlogloss:0.02377\n",
            "[377]\tvalidation_0-mlogloss:0.00137\tvalidation_1-mlogloss:0.02377\n",
            "[378]\tvalidation_0-mlogloss:0.00137\tvalidation_1-mlogloss:0.02376\n",
            "[379]\tvalidation_0-mlogloss:0.00137\tvalidation_1-mlogloss:0.02376\n",
            "[380]\tvalidation_0-mlogloss:0.00136\tvalidation_1-mlogloss:0.02375\n",
            "[381]\tvalidation_0-mlogloss:0.00136\tvalidation_1-mlogloss:0.02375\n",
            "[382]\tvalidation_0-mlogloss:0.00136\tvalidation_1-mlogloss:0.02373\n",
            "[383]\tvalidation_0-mlogloss:0.00136\tvalidation_1-mlogloss:0.02372\n",
            "[384]\tvalidation_0-mlogloss:0.00136\tvalidation_1-mlogloss:0.02372\n",
            "[385]\tvalidation_0-mlogloss:0.00136\tvalidation_1-mlogloss:0.02370\n",
            "[386]\tvalidation_0-mlogloss:0.00136\tvalidation_1-mlogloss:0.02369\n",
            "[387]\tvalidation_0-mlogloss:0.00136\tvalidation_1-mlogloss:0.02366\n",
            "[388]\tvalidation_0-mlogloss:0.00136\tvalidation_1-mlogloss:0.02366\n",
            "[389]\tvalidation_0-mlogloss:0.00136\tvalidation_1-mlogloss:0.02366\n",
            "[390]\tvalidation_0-mlogloss:0.00136\tvalidation_1-mlogloss:0.02366\n",
            "[391]\tvalidation_0-mlogloss:0.00136\tvalidation_1-mlogloss:0.02365\n",
            "[392]\tvalidation_0-mlogloss:0.00136\tvalidation_1-mlogloss:0.02362\n",
            "[393]\tvalidation_0-mlogloss:0.00136\tvalidation_1-mlogloss:0.02363\n",
            "[394]\tvalidation_0-mlogloss:0.00135\tvalidation_1-mlogloss:0.02364\n",
            "[395]\tvalidation_0-mlogloss:0.00135\tvalidation_1-mlogloss:0.02363\n",
            "[396]\tvalidation_0-mlogloss:0.00135\tvalidation_1-mlogloss:0.02362\n",
            "[397]\tvalidation_0-mlogloss:0.00135\tvalidation_1-mlogloss:0.02363\n",
            "[398]\tvalidation_0-mlogloss:0.00135\tvalidation_1-mlogloss:0.02365\n",
            "[399]\tvalidation_0-mlogloss:0.00135\tvalidation_1-mlogloss:0.02364\n",
            "[400]\tvalidation_0-mlogloss:0.00135\tvalidation_1-mlogloss:0.02364\n",
            "[401]\tvalidation_0-mlogloss:0.00135\tvalidation_1-mlogloss:0.02365\n",
            "[402]\tvalidation_0-mlogloss:0.00135\tvalidation_1-mlogloss:0.02364\n",
            "[403]\tvalidation_0-mlogloss:0.00135\tvalidation_1-mlogloss:0.02365\n",
            "[404]\tvalidation_0-mlogloss:0.00135\tvalidation_1-mlogloss:0.02365\n",
            "[405]\tvalidation_0-mlogloss:0.00135\tvalidation_1-mlogloss:0.02367\n",
            "[406]\tvalidation_0-mlogloss:0.00135\tvalidation_1-mlogloss:0.02366\n",
            "[407]\tvalidation_0-mlogloss:0.00135\tvalidation_1-mlogloss:0.02367\n",
            "[408]\tvalidation_0-mlogloss:0.00135\tvalidation_1-mlogloss:0.02365\n",
            "[409]\tvalidation_0-mlogloss:0.00135\tvalidation_1-mlogloss:0.02365\n",
            "[410]\tvalidation_0-mlogloss:0.00135\tvalidation_1-mlogloss:0.02364\n",
            "[411]\tvalidation_0-mlogloss:0.00135\tvalidation_1-mlogloss:0.02364\n",
            "[412]\tvalidation_0-mlogloss:0.00135\tvalidation_1-mlogloss:0.02363\n",
            "[413]\tvalidation_0-mlogloss:0.00135\tvalidation_1-mlogloss:0.02364\n",
            "[414]\tvalidation_0-mlogloss:0.00134\tvalidation_1-mlogloss:0.02364\n",
            "[415]\tvalidation_0-mlogloss:0.00134\tvalidation_1-mlogloss:0.02364\n",
            "[416]\tvalidation_0-mlogloss:0.00134\tvalidation_1-mlogloss:0.02363\n",
            "[417]\tvalidation_0-mlogloss:0.00134\tvalidation_1-mlogloss:0.02364\n",
            "[418]\tvalidation_0-mlogloss:0.00134\tvalidation_1-mlogloss:0.02365\n",
            "[419]\tvalidation_0-mlogloss:0.00134\tvalidation_1-mlogloss:0.02364\n",
            "[420]\tvalidation_0-mlogloss:0.00134\tvalidation_1-mlogloss:0.02364\n",
            "[421]\tvalidation_0-mlogloss:0.00134\tvalidation_1-mlogloss:0.02365\n",
            "[422]\tvalidation_0-mlogloss:0.00134\tvalidation_1-mlogloss:0.02367\n",
            "[423]\tvalidation_0-mlogloss:0.00134\tvalidation_1-mlogloss:0.02367\n",
            "[424]\tvalidation_0-mlogloss:0.00134\tvalidation_1-mlogloss:0.02366\n",
            "[425]\tvalidation_0-mlogloss:0.00134\tvalidation_1-mlogloss:0.02363\n",
            "[426]\tvalidation_0-mlogloss:0.00134\tvalidation_1-mlogloss:0.02363\n",
            "[427]\tvalidation_0-mlogloss:0.00134\tvalidation_1-mlogloss:0.02363\n",
            "[428]\tvalidation_0-mlogloss:0.00134\tvalidation_1-mlogloss:0.02363\n",
            "[429]\tvalidation_0-mlogloss:0.00134\tvalidation_1-mlogloss:0.02361\n",
            "[430]\tvalidation_0-mlogloss:0.00134\tvalidation_1-mlogloss:0.02361\n",
            "[431]\tvalidation_0-mlogloss:0.00134\tvalidation_1-mlogloss:0.02363\n",
            "[432]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02361\n",
            "[433]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02359\n",
            "[434]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02359\n",
            "[435]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02361\n",
            "[436]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02361\n",
            "[437]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02361\n",
            "[438]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02362\n",
            "[439]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02361\n",
            "[440]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02359\n",
            "[441]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02360\n",
            "[442]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02359\n",
            "[443]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02359\n",
            "[444]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02359\n",
            "[445]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02357\n",
            "[446]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02355\n",
            "[447]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02355\n",
            "[448]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02356\n",
            "[449]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02356\n",
            "[450]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02356\n",
            "[451]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02355\n",
            "[452]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02354\n",
            "[453]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02355\n",
            "[454]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02354\n",
            "[455]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02356\n",
            "[456]\tvalidation_0-mlogloss:0.00133\tvalidation_1-mlogloss:0.02356\n",
            "[457]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02355\n",
            "[458]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02355\n",
            "[459]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02354\n",
            "[460]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02354\n",
            "[461]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02353\n",
            "[462]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02355\n",
            "[463]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02354\n",
            "[464]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02355\n",
            "[465]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02355\n",
            "[466]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02355\n",
            "[467]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02355\n",
            "[468]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02354\n",
            "[469]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02354\n",
            "[470]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02356\n",
            "[471]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02356\n",
            "[472]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02357\n",
            "[473]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02357\n",
            "[474]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02357\n",
            "[475]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02356\n",
            "[476]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02354\n",
            "[477]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02356\n",
            "[478]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02357\n",
            "[479]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02358\n",
            "[480]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02357\n",
            "[481]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02357\n",
            "[482]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02356\n",
            "[483]\tvalidation_0-mlogloss:0.00132\tvalidation_1-mlogloss:0.02358\n",
            "[484]\tvalidation_0-mlogloss:0.00131\tvalidation_1-mlogloss:0.02360\n",
            "[485]\tvalidation_0-mlogloss:0.00131\tvalidation_1-mlogloss:0.02360\n",
            "[486]\tvalidation_0-mlogloss:0.00131\tvalidation_1-mlogloss:0.02361\n",
            "[487]\tvalidation_0-mlogloss:0.00131\tvalidation_1-mlogloss:0.02362\n",
            "[488]\tvalidation_0-mlogloss:0.00131\tvalidation_1-mlogloss:0.02362\n",
            "[489]\tvalidation_0-mlogloss:0.00131\tvalidation_1-mlogloss:0.02364\n",
            "[490]\tvalidation_0-mlogloss:0.00131\tvalidation_1-mlogloss:0.02365\n",
            "[491]\tvalidation_0-mlogloss:0.00131\tvalidation_1-mlogloss:0.02365\n",
            "[492]\tvalidation_0-mlogloss:0.00131\tvalidation_1-mlogloss:0.02365\n",
            "[493]\tvalidation_0-mlogloss:0.00131\tvalidation_1-mlogloss:0.02364\n",
            "[494]\tvalidation_0-mlogloss:0.00131\tvalidation_1-mlogloss:0.02364\n",
            "[495]\tvalidation_0-mlogloss:0.00131\tvalidation_1-mlogloss:0.02363\n",
            "[496]\tvalidation_0-mlogloss:0.00131\tvalidation_1-mlogloss:0.02362\n",
            "[497]\tvalidation_0-mlogloss:0.00131\tvalidation_1-mlogloss:0.02361\n",
            "[498]\tvalidation_0-mlogloss:0.00131\tvalidation_1-mlogloss:0.02361\n",
            "[499]\tvalidation_0-mlogloss:0.00131\tvalidation_1-mlogloss:0.02360\n",
            "Saving xgb_model...\n",
            " - Native saved: xgb_model\n",
            "\n",
            "========================================\n",
            "3. LSTM\n",
            "========================================\n",
            "Starting Random Search (n_iter=3)...\n",
            "Trial 1/3: {'units': 32, 'dropout': 0.2, 'lr': 0.001}\n",
            " - Val Acc: 0.9199\n",
            "Trial 2/3: {'units': 64, 'dropout': 0.2, 'lr': 0.01}\n",
            " - Val Acc: 0.9800\n",
            "Trial 3/3: {'units': 64, 'dropout': 0.4, 'lr': 0.01}\n",
            " - Val Acc: 0.9690\n",
            "Best Params: {'units': 64, 'dropout': 0.2, 'lr': 0.01} (Val Acc: 0.9800)\n",
            "Training final LSTM...\n",
            "Epoch 1/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 127ms/step - accuracy: 0.6210 - loss: 1.1400 - val_accuracy: 0.8397 - val_loss: 0.3984 - learning_rate: 0.0100\n",
            "Epoch 2/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.8554 - loss: 0.4138 - val_accuracy: 0.9053 - val_loss: 0.2682 - learning_rate: 0.0100\n",
            "Epoch 3/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.9127 - loss: 0.2491 - val_accuracy: 0.9526 - val_loss: 0.1976 - learning_rate: 0.0100\n",
            "Epoch 4/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.9334 - loss: 0.2035 - val_accuracy: 0.8889 - val_loss: 0.2692 - learning_rate: 0.0100\n",
            "Epoch 5/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - accuracy: 0.9044 - loss: 0.2410 - val_accuracy: 0.9326 - val_loss: 0.1869 - learning_rate: 0.0100\n",
            "Epoch 6/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - accuracy: 0.9447 - loss: 0.1648 - val_accuracy: 0.9563 - val_loss: 0.1247 - learning_rate: 0.0100\n",
            "Epoch 7/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.9600 - loss: 0.1201 - val_accuracy: 0.9745 - val_loss: 0.0857 - learning_rate: 0.0100\n",
            "Epoch 8/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 160ms/step - accuracy: 0.9779 - loss: 0.0647 - val_accuracy: 0.9709 - val_loss: 0.0848 - learning_rate: 0.0100\n",
            "Epoch 9/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 134ms/step - accuracy: 0.9824 - loss: 0.0488 - val_accuracy: 0.9763 - val_loss: 0.0813 - learning_rate: 0.0100\n",
            "Epoch 10/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - accuracy: 0.9766 - loss: 0.0810 - val_accuracy: 0.9490 - val_loss: 0.1685 - learning_rate: 0.0100\n",
            "Epoch 11/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - accuracy: 0.9673 - loss: 0.0916 - val_accuracy: 0.9654 - val_loss: 0.1116 - learning_rate: 0.0100\n",
            "Epoch 12/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.8128 - loss: 0.5881\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 136ms/step - accuracy: 0.8132 - loss: 0.5867 - val_accuracy: 0.9381 - val_loss: 0.1870 - learning_rate: 0.0100\n",
            "Epoch 13/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 130ms/step - accuracy: 0.9411 - loss: 0.1982 - val_accuracy: 0.9599 - val_loss: 0.1310 - learning_rate: 0.0050\n",
            "Epoch 14/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - accuracy: 0.9703 - loss: 0.1043 - val_accuracy: 0.9818 - val_loss: 0.0752 - learning_rate: 0.0050\n",
            "Epoch 15/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 129ms/step - accuracy: 0.9850 - loss: 0.0628 - val_accuracy: 0.9818 - val_loss: 0.0715 - learning_rate: 0.0050\n",
            "Epoch 16/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.9895 - loss: 0.0470 - val_accuracy: 0.9836 - val_loss: 0.0663 - learning_rate: 0.0050\n",
            "Epoch 17/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.9908 - loss: 0.0353 - val_accuracy: 0.9872 - val_loss: 0.0564 - learning_rate: 0.0050\n",
            "Epoch 18/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - accuracy: 0.9919 - loss: 0.0288 - val_accuracy: 0.9909 - val_loss: 0.0458 - learning_rate: 0.0050\n",
            "Epoch 19/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.9960 - loss: 0.0196 - val_accuracy: 0.9872 - val_loss: 0.0496 - learning_rate: 0.0050\n",
            "Epoch 20/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.9940 - loss: 0.0196 - val_accuracy: 0.9854 - val_loss: 0.0659 - learning_rate: 0.0050\n",
            "Epoch 21/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.9955 - loss: 0.0194\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.9955 - loss: 0.0195 - val_accuracy: 0.9781 - val_loss: 0.0612 - learning_rate: 0.0050\n",
            "Epoch 22/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - accuracy: 0.9900 - loss: 0.0292 - val_accuracy: 0.9927 - val_loss: 0.0370 - learning_rate: 0.0025\n",
            "Epoch 23/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.9955 - loss: 0.0167 - val_accuracy: 0.9927 - val_loss: 0.0371 - learning_rate: 0.0025\n",
            "Epoch 24/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.9948 - loss: 0.0161 - val_accuracy: 0.9945 - val_loss: 0.0297 - learning_rate: 0.0025\n",
            "Epoch 25/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.9987 - loss: 0.0079 - val_accuracy: 0.9964 - val_loss: 0.0275 - learning_rate: 0.0025\n",
            "Epoch 26/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - accuracy: 0.9976 - loss: 0.0110 - val_accuracy: 0.9964 - val_loss: 0.0268 - learning_rate: 0.0025\n",
            "Epoch 27/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 120ms/step - accuracy: 0.9992 - loss: 0.0060 - val_accuracy: 0.9964 - val_loss: 0.0255 - learning_rate: 0.0025\n",
            "Epoch 28/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.9991 - loss: 0.0056 - val_accuracy: 0.9964 - val_loss: 0.0257 - learning_rate: 0.0025\n",
            "Epoch 29/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 135ms/step - accuracy: 0.9995 - loss: 0.0044 - val_accuracy: 0.9964 - val_loss: 0.0234 - learning_rate: 0.0025\n",
            "Epoch 30/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 129ms/step - accuracy: 0.9996 - loss: 0.0047 - val_accuracy: 0.9927 - val_loss: 0.0382 - learning_rate: 0.0025\n",
            "Epoch 31/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - accuracy: 0.9994 - loss: 0.0038 - val_accuracy: 0.9964 - val_loss: 0.0218 - learning_rate: 0.0025\n",
            "Epoch 32/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - accuracy: 0.9908 - loss: 0.0278 - val_accuracy: 0.9836 - val_loss: 0.0473 - learning_rate: 0.0025\n",
            "Epoch 33/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - accuracy: 0.9976 - loss: 0.0139 - val_accuracy: 0.9872 - val_loss: 0.0382 - learning_rate: 0.0025\n",
            "Epoch 34/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.9976 - loss: 0.0102\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.9976 - loss: 0.0102 - val_accuracy: 0.9854 - val_loss: 0.0321 - learning_rate: 0.0025\n",
            "Epoch 35/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.9981 - loss: 0.0088 - val_accuracy: 0.9872 - val_loss: 0.0300 - learning_rate: 0.0012\n",
            "Epoch 36/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - accuracy: 0.9987 - loss: 0.0054 - val_accuracy: 0.9927 - val_loss: 0.0255 - learning_rate: 0.0012\n",
            "Epoch 36: early stopping\n",
            "Restoring model weights from the end of the best epoch: 31.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving lstm_model...\n",
            " - Native saved: lstm_model\n",
            "\n",
            "========================================\n",
            "4. CNN\n",
            "========================================\n",
            "Starting Random Search (n_iter=3)...\n",
            "Trial 1/3: {'filters': 64, 'kernel_size': 5, 'lr': 0.001}\n",
            " - Val Acc: 0.9909\n",
            "Trial 2/3: {'filters': 64, 'kernel_size': 3, 'lr': 0.001}\n",
            " - Val Acc: 0.9581\n",
            "Trial 3/3: {'filters': 64, 'kernel_size': 3, 'lr': 0.001}\n",
            " - Val Acc: 0.9818\n",
            "Best Params: {'filters': 64, 'kernel_size': 5, 'lr': 0.001} (Val Acc: 0.9909)\n",
            "Training final CNN...\n",
            "Epoch 1/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.5530 - loss: 2.3658 - val_accuracy: 0.9745 - val_loss: 0.1350 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9699 - loss: 0.1267 - val_accuracy: 0.9672 - val_loss: 0.1026 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9622 - loss: 0.1345 - val_accuracy: 0.9872 - val_loss: 0.0530 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 46ms/step - accuracy: 0.9854 - loss: 0.0516 - val_accuracy: 0.9872 - val_loss: 0.0370 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9932 - loss: 0.0273 - val_accuracy: 0.9690 - val_loss: 0.1544 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 0.9920 - loss: 0.0283 - val_accuracy: 0.9927 - val_loss: 0.0291 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9957 - loss: 0.0178 - val_accuracy: 0.9836 - val_loss: 0.0557 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.9855 - loss: 0.0527 - val_accuracy: 0.9945 - val_loss: 0.0266 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.9983 - loss: 0.0107 - val_accuracy: 0.9945 - val_loss: 0.0297 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 30ms/step - accuracy: 0.9942 - loss: 0.0179 - val_accuracy: 0.9763 - val_loss: 0.1067 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m77/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9859 - loss: 0.0518\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9859 - loss: 0.0517 - val_accuracy: 0.9836 - val_loss: 0.0743 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.9927 - loss: 0.0243 - val_accuracy: 0.9927 - val_loss: 0.0321 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 48ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.9945 - val_loss: 0.0193 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 31ms/step - accuracy: 0.9983 - loss: 0.0054 - val_accuracy: 0.9927 - val_loss: 0.0273 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9995 - loss: 0.0036 - val_accuracy: 0.9927 - val_loss: 0.0244 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m77/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0021\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9945 - val_loss: 0.0208 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 47ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9927 - val_loss: 0.0268 - learning_rate: 2.5000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.9945 - val_loss: 0.0237 - learning_rate: 2.5000e-04\n",
            "Epoch 18: early stopping\n",
            "Restoring model weights from the end of the best epoch: 13.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving cnn_model...\n",
            " - Native saved: cnn_model\n",
            "\n",
            "========================================\n",
            "5. Transformer\n",
            "========================================\n",
            "Starting Random Search (n_iter=3)...\n",
            "Trial 1/3: {'head_size': 64, 'num_heads': 2, 'dropout': 0.1, 'lr': 0.001}\n",
            " - Val Acc: 0.9745\n",
            "Trial 2/3: {'head_size': 64, 'num_heads': 2, 'dropout': 0.1, 'lr': 0.001}\n",
            " - Val Acc: 0.9690\n",
            "Trial 3/3: {'head_size': 64, 'num_heads': 2, 'dropout': 0.1, 'lr': 0.001}\n",
            " - Val Acc: 0.9690\n",
            "Best Params: {'head_size': 64, 'num_heads': 2, 'dropout': 0.1, 'lr': 0.001} (Val Acc: 0.9745)\n",
            "Training final Transformer...\n",
            "Epoch 1/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 129ms/step - accuracy: 0.3357 - loss: 3.5765 - val_accuracy: 0.8506 - val_loss: 0.5756 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 108ms/step - accuracy: 0.8318 - loss: 0.6043 - val_accuracy: 0.9381 - val_loss: 0.1974 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 122ms/step - accuracy: 0.9082 - loss: 0.2930 - val_accuracy: 0.9599 - val_loss: 0.1249 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 123ms/step - accuracy: 0.9312 - loss: 0.2226 - val_accuracy: 0.9672 - val_loss: 0.0949 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - accuracy: 0.9454 - loss: 0.1658 - val_accuracy: 0.9745 - val_loss: 0.0827 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - accuracy: 0.9600 - loss: 0.1356 - val_accuracy: 0.9800 - val_loss: 0.0695 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - accuracy: 0.9655 - loss: 0.1179 - val_accuracy: 0.9781 - val_loss: 0.0655 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.9706 - loss: 0.0905 - val_accuracy: 0.9836 - val_loss: 0.0498 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.9736 - loss: 0.0778 - val_accuracy: 0.9836 - val_loss: 0.0493 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 125ms/step - accuracy: 0.9708 - loss: 0.0849 - val_accuracy: 0.9854 - val_loss: 0.0355 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.9749 - loss: 0.0794 - val_accuracy: 0.9891 - val_loss: 0.0313 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - accuracy: 0.9761 - loss: 0.0774 - val_accuracy: 0.9800 - val_loss: 0.0384 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.9823 - loss: 0.0572 - val_accuracy: 0.9872 - val_loss: 0.0313 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m77/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.9816 - loss: 0.0609\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 126ms/step - accuracy: 0.9816 - loss: 0.0607 - val_accuracy: 0.9800 - val_loss: 0.0499 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.9842 - loss: 0.0466 - val_accuracy: 0.9818 - val_loss: 0.0297 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - accuracy: 0.9886 - loss: 0.0407 - val_accuracy: 0.9836 - val_loss: 0.0326 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 108ms/step - accuracy: 0.9873 - loss: 0.0400 - val_accuracy: 0.9872 - val_loss: 0.0303 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m77/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.9875 - loss: 0.0377\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.9875 - loss: 0.0376 - val_accuracy: 0.9836 - val_loss: 0.0355 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.9885 - loss: 0.0364 - val_accuracy: 0.9854 - val_loss: 0.0305 - learning_rate: 2.5000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - accuracy: 0.9933 - loss: 0.0290 - val_accuracy: 0.9836 - val_loss: 0.0292 - learning_rate: 2.5000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.9870 - loss: 0.0370 - val_accuracy: 0.9891 - val_loss: 0.0275 - learning_rate: 2.5000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - accuracy: 0.9929 - loss: 0.0310 - val_accuracy: 0.9854 - val_loss: 0.0276 - learning_rate: 2.5000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.9916 - loss: 0.0273 - val_accuracy: 0.9854 - val_loss: 0.0255 - learning_rate: 2.5000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - accuracy: 0.9920 - loss: 0.0297 - val_accuracy: 0.9854 - val_loss: 0.0279 - learning_rate: 2.5000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 110ms/step - accuracy: 0.9919 - loss: 0.0258 - val_accuracy: 0.9872 - val_loss: 0.0259 - learning_rate: 2.5000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.9936 - loss: 0.0258 - val_accuracy: 0.9945 - val_loss: 0.0175 - learning_rate: 2.5000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.9924 - loss: 0.0268 - val_accuracy: 0.9854 - val_loss: 0.0297 - learning_rate: 2.5000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - accuracy: 0.9934 - loss: 0.0221 - val_accuracy: 0.9854 - val_loss: 0.0288 - learning_rate: 2.5000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - accuracy: 0.9934 - loss: 0.0245 - val_accuracy: 0.9927 - val_loss: 0.0169 - learning_rate: 2.5000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.9916 - loss: 0.0261 - val_accuracy: 0.9872 - val_loss: 0.0247 - learning_rate: 2.5000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.9936 - loss: 0.0244 - val_accuracy: 0.9909 - val_loss: 0.0188 - learning_rate: 2.5000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m77/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.9929 - loss: 0.0261\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - accuracy: 0.9930 - loss: 0.0260 - val_accuracy: 0.9909 - val_loss: 0.0178 - learning_rate: 2.5000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - accuracy: 0.9944 - loss: 0.0212 - val_accuracy: 0.9891 - val_loss: 0.0199 - learning_rate: 1.2500e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.9963 - loss: 0.0178 - val_accuracy: 0.9945 - val_loss: 0.0155 - learning_rate: 1.2500e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.9970 - loss: 0.0176 - val_accuracy: 0.9891 - val_loss: 0.0241 - learning_rate: 1.2500e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.9930 - loss: 0.0204 - val_accuracy: 0.9927 - val_loss: 0.0145 - learning_rate: 1.2500e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 128ms/step - accuracy: 0.9959 - loss: 0.0181 - val_accuracy: 0.9945 - val_loss: 0.0142 - learning_rate: 1.2500e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.9966 - loss: 0.0157 - val_accuracy: 0.9927 - val_loss: 0.0195 - learning_rate: 1.2500e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - accuracy: 0.9934 - loss: 0.0220 - val_accuracy: 0.9927 - val_loss: 0.0209 - learning_rate: 1.2500e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.9950 - loss: 0.0184 - val_accuracy: 0.9945 - val_loss: 0.0132 - learning_rate: 1.2500e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 139ms/step - accuracy: 0.9963 - loss: 0.0172 - val_accuracy: 0.9909 - val_loss: 0.0191 - learning_rate: 1.2500e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 125ms/step - accuracy: 0.9972 - loss: 0.0136 - val_accuracy: 0.9927 - val_loss: 0.0163 - learning_rate: 1.2500e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m77/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - accuracy: 0.9964 - loss: 0.0153\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 126ms/step - accuracy: 0.9964 - loss: 0.0153 - val_accuracy: 0.9927 - val_loss: 0.0155 - learning_rate: 1.2500e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - accuracy: 0.9943 - loss: 0.0173 - val_accuracy: 0.9927 - val_loss: 0.0179 - learning_rate: 6.2500e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m78/78\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.9944 - loss: 0.0173 - val_accuracy: 0.9927 - val_loss: 0.0200 - learning_rate: 6.2500e-05\n",
            "Epoch 45: early stopping\n",
            "Restoring model weights from the end of the best epoch: 40.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving transformer_model...\n",
            " - Native saved: transformer_model\n",
            "\n",
            "All models trained, tuned, and saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-nBVZOBT5Hss"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}